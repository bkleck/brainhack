{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-2TQ7eobEqs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "f25b72ca-5744-4ee1-b209-fef313b2e85f"
      },
      "source": [
        "!pip install object-detection-fastai\n",
        "!pip install git+https://github.com/ildoonet/pytorch-randaugment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting object-detection-fastai\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/ec/153a9ace353992e2913178d8c42110209bf9c5debc8338c943580d73416f/object-detection-fastai-0.0.6.tar.gz\n",
            "Building wheels for collected packages: object-detection-fastai\n",
            "  Building wheel for object-detection-fastai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection-fastai: filename=object_detection_fastai-0.0.6-cp36-none-any.whl size=31580 sha256=a9718db25259d8a587802a26e8515332f4e49231612fa1caac9af9efbb96d200\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/79/9c/7299e94e248a7102202b922f02da86502f2e6e35dbe07706c8\n",
            "Successfully built object-detection-fastai\n",
            "Installing collected packages: object-detection-fastai\n",
            "Successfully installed object-detection-fastai-0.0.6\n",
            "Collecting git+https://github.com/ildoonet/pytorch-randaugment\n",
            "  Cloning https://github.com/ildoonet/pytorch-randaugment to /tmp/pip-req-build-rs5e019m\n",
            "  Running command git clone -q https://github.com/ildoonet/pytorch-randaugment /tmp/pip-req-build-rs5e019m\n",
            "Building wheels for collected packages: RandAugment\n",
            "  Building wheel for RandAugment (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for RandAugment: filename=RandAugment-0.1-cp36-none-any.whl size=24211 sha256=8be83800037732e82f426d06e31b87f557de35be426e1e03ef874d3bb4b35909\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k1xx88ft/wheels/0d/0e/e9/f8b70c1e233491338d524d867a7e959d10bb14a16bd5379b09\n",
            "Successfully built RandAugment\n",
            "Installing collected packages: RandAugment\n",
            "Successfully installed RandAugment-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1motS0jcGr-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "da85689e-e658-4c2d-9067-9a9921a3ae62"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VxKO7VPx21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c63329ef-bcd5-4a92-856e-0852097866f7"
      },
      "source": [
        "import torch\n",
        "torch.cuda.get_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla P4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMTPQjlHhI5K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "a1bb5708-ab6d-4276-86a3-07306c919f07"
      },
      "source": [
        "%cd /content/drive/My Drive/BrainHack/YOLO/\n",
        "\n",
        "from __future__ import division\n",
        "\n",
        "from models import *\n",
        "from utils.logger import *\n",
        "from utils.utils import *\n",
        "from utils.datasets import *\n",
        "from utils.parse_config import *\n",
        "from test import evaluate\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # os.makedirs(\"output\", exist_ok=True)\n",
        "    # os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "    # Get data configuration\n",
        "    data_config = parse_data_config(\"config/coco.data\")\n",
        "    train_path = data_config[\"train\"]\n",
        "    valid_path = data_config[\"valid\"]\n",
        "    class_names = load_classes(data_config[\"names\"])\n",
        "\n",
        "    EPOCH = 1\n",
        "    BATCH_SIZE = 2 # 32 might be too big for Colab to handle. 16 too.\n",
        "    GRAD_ACCUMULATE = 2\n",
        "    MODEL_DEF = \"config/yolov3.cfg\"\n",
        "    PRETRAINED_WEIGHTS = \"/content/drive/My Drive/BrainHack/yolov3.weights\"\n",
        "    N_CPU = 8\n",
        "    IMG_SIZE = 416\n",
        "    checkpoint_interval = 1\n",
        "    evaluation_interval = 1\n",
        "    compute_mAP = True\n",
        "    multiscale_training = True\n",
        "\n",
        "    # Initiate model\n",
        "    model = Darknet(MODEL_DEF).to(device)\n",
        "    model.apply(weights_init_normal)\n",
        "\n",
        "    # If specified we start from checkpoint\n",
        "    if PRETRAINED_WEIGHTS:\n",
        "        if PRETRAINED_WEIGHTS.endswith(\".pth\"):\n",
        "            model.load_state_dict(torch.load(PRETRAINED_WEIGHTS))\n",
        "        else:\n",
        "            model.load_darknet_weights(PRETRAINED_WEIGHTS)\n",
        "\n",
        "    # Get dataloader\n",
        "    dataset = ListDataset(train_path, augment=True, multiscale=multiscale_training)\n",
        "    dataloader = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=N_CPU,\n",
        "        pin_memory=True,\n",
        "        collate_fn=dataset.collate_fn,\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    # scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.03, steps_per_epoch=len(dataloader), epochs=10)\n",
        "\n",
        "    metrics = [\n",
        "        \"grid_size\",\n",
        "        \"loss\",\n",
        "        \"x\",\n",
        "        \"y\",\n",
        "        \"w\",\n",
        "        \"h\",\n",
        "        \"conf\",\n",
        "        \"cls\",\n",
        "        \"cls_acc\",\n",
        "        \"recall50\",\n",
        "        \"recall75\",\n",
        "        \"precision\",\n",
        "        \"conf_obj\",\n",
        "        \"conf_noobj\",\n",
        "    ]\n",
        "  # /content/drive/My Drive/BrainHack/Data/train/train/__image_na\n",
        "\n",
        "    for epoch in range(EPOCH):\n",
        "        model.train()\n",
        "        start_time = time.time()\n",
        "        for batch_i, (_, imgs, targets) in enumerate(dataloader):\n",
        "            batches_done = len(dataloader) * epoch + batch_i\n",
        "\n",
        "            imgs = Variable(imgs.to(device))\n",
        "            targets = Variable(targets.to(device), requires_grad=False)\n",
        "\n",
        "            loss, outputs = model(imgs, targets)\n",
        "            loss.backward()\n",
        "\n",
        "            if batches_done % GRAD_ACCUMULATE:\n",
        "                # Accumulates gradient before each step\n",
        "                optimizer.step()\n",
        "                # scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            # ----------------\n",
        "            #   Log progress\n",
        "            # ----------------\n",
        "\n",
        "            log_str = \"\\n---- [Epoch %d/%d, Batch %d/%d] ----\\n\" % (epoch, EPOCH, batch_i, len(dataloader))\n",
        "\n",
        "            metric_table = [[\"Metrics\", *[f\"YOLO Layer {i}\" for i in range(len(model.yolo_layers))]]]\n",
        "\n",
        "            # Log metrics at each YOLO layer\n",
        "            for i, metric in enumerate(metrics):\n",
        "                formats = {m: \"%.6f\" for m in metrics}\n",
        "                formats[\"grid_size\"] = \"%2d\"\n",
        "                formats[\"cls_acc\"] = \"%.2f%%\"\n",
        "                row_metrics = [formats[metric] % yolo.metrics.get(metric, 0) for yolo in model.yolo_layers]\n",
        "                metric_table += [[metric, *row_metrics]]\n",
        "\n",
        "            # Determine approximate time left for epoch\n",
        "            epoch_batches_left = len(dataloader) - (batch_i + 1)\n",
        "            time_left = datetime.timedelta(seconds=epoch_batches_left * (time.time() - start_time) / (batch_i + 1))\n",
        "\n",
        "            model.seen += imgs.size(0)\n",
        "\n",
        "        if epoch % evaluation_interval == 0:\n",
        "            print(\"\\n---- Evaluating Model ----\")\n",
        "            # Evaluate the model on the validation set\n",
        "            precision, recall, AP, f1, ap_class = evaluate(\n",
        "                model,\n",
        "                path=valid_path,\n",
        "                iou_thres=0.5,\n",
        "                conf_thres=0.5,\n",
        "                nms_thres=0.5,\n",
        "                img_size=IMG_SIZE,\n",
        "                batch_size=BATCH_SIZE,\n",
        "            )\n",
        "            evaluation_metrics = [\n",
        "                (\"val_precision\", precision.mean()),\n",
        "                (\"val_recall\", recall.mean()),\n",
        "                (\"val_mAP\", AP.mean()),\n",
        "                (\"val_f1\", f1.mean()),\n",
        "            ]\n",
        "\n",
        "            # Print class APs and mAP\n",
        "            ap_table = [[\"Index\", \"Class name\", \"AP\"]]\n",
        "            for i, c in enumerate(ap_class):\n",
        "                ap_table += [[c, class_names[c], \"%.5f\" % AP[i]]]\n",
        "            print(f\"---- mAP {AP.mean()}\")\n",
        "\n",
        "        if epoch % checkpoint_interval == 0:\n",
        "            torch.save(model.state_dict(), f\"checkpoints/yolov3_ckpt_%d.pth\" % epoch)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/16JDsNEOXVr1AV5ftUzRu4LTl3Mla2W8b/BrainHack/YOLO\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:2766: DecompressionBombWarning: Image size (123871510 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  DecompressionBombWarning,\n",
            "Detecting objects:   0%|          | 0/737 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---- Evaluating Model ----\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rDetecting objects:   0%|          | 0/737 [00:02<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "---- mAP 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}